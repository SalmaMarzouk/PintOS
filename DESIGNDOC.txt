			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Ahmed Talaat Noser 	<ahmednoser1@gmail.com>
Ereny Zarief   	<erinyzarif3@gmail.com>
Salma Ragab 		<salma.ragab.gad@gmail.com>
Maria Onsi 		<mariaonsy.3@gmail.com>
Nada Fathy 		<nadafathy853@gmail.com>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
Answer:
->struct thread: 'endTime' variable is added to identify the time in which we unblock the sleeping thread.
->struct list 'sleeping': global list to store the sleeping (blocked)threads.



---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.
Answer:
..When calling timer_sleep function, 
	endTime variable of the current thread is assigned to be =number of ticks for which the the thread will be sleeping + current number of ticks(current time).
..Insert the thread in sleeping list in ascending order according to end of blocking time.
..Then, just disable the interrupt and block the thread. 



>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?
Answer:
..In timer interrupt function we loop over the 'sleeping'list which includes all sleeping threads
..Then we check that if blocking time of the first thread in the list (which will be unblocked earlier than all other sleeping threads) has not yet finished,
	end looping over threads . That's because all other threads ,of course, have larger end time than the first thread. 
..But if we reached or exceeded the end time of the first thread , we remove it from the sleeping list and unblock it also.



---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?
Answer: the interrupt is disabled in timer_sleep().


>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?
Answer: the interrupt is disabled



---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
Answer: we first did it by looping on the list of all threads and check if the thread is blocked and its block time is ended, unblock it.
	but we found that it's better to make an ordered list(by block time) for only blocked threads and check if a thread reached its end time.

    PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
  ->B1: New defined in struct thread:
         •Effective priority: initialized with same value of priority,
                 during execution change to be maximum donated priority.
         •Holeded_locks: list of locks holded by the thread.
         •Aquired_locks: the lock which the thread wait.
        New defined in struct lock:
         •Priority: initialized with minimum priority, during
                   execution change to be maximum waiting thread priority.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)
  ->B2: int (named effective priority) to track priority donation,
         holded_locks, and aquired_locks.

                           L1  ---> T5  <--- L3
                          / | \
		        T3  | T1

                            T2  <--- L2 
                                     |                                                          
                                     T4
        L: notation for locks.
        T: notation for threads.
        Straight line means: thread is waiting for lock.
        Directed line means: thread is holding lock. 


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
  ->B3: using ordered list of waiters, inserting new waiters descendingly 
        according to effective priority, this will maintain round-robin technique. 

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
  ->B4: When new thread acquires lock and its priority is greater than lock’s 
        priority, change lock’s priority and priority of thread holding lock and
        iterate over all locks the holding thread waiting for and change its 
        priority and check for their holders and change their priority and so on. 

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
  ->B5: if thread ‘a’ releases lock:
         •If the thread’s priority is donated from that lock: change effective
          priority of ‘a’ to the maximum of its priority and maximum priority of 
          locks that ‘a’ waiting for. If the list holded locks thread ‘a’ waiting
          is empty change effective priority of ‘a’ to thread ‘a’ priority.
         •Take waiter with maximum effective priority and change the lock priority
          to the maximum waiter thread priority. If there is no waiters, 
          set lock priority to its minimum value.



---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?
   ->B6: if thread ‘a’ changes its priority and it’s interrupted 
        (before setting the new value which is maximum over other threads) 
        by timer interrupt to schedule another thread to be executed, 
        In this case scheduler won’t schedule thread ‘a’, so using 
        intr_disable will avoid potential race.
        Lock can maintain that no other thread would change its priority 
        while thread ’a’ holding lock but this can’t solve previous problem of scheduling.



---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered? 
  ->B7: It’s easy to implement, think and keep track of threads. 

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
Answer:
> typedef: fp ----> for real values (recent_cpu & load_avg)
> struct thread: recent_ cpu ----> to descripe the amount of CPU time a thread has received recently.
> struct thread: nice ----> nice value that determines how "nice" the thread should be to other threads.
> in thread.h: load_avg ----> descripes the average number of threads ready to run over the past minute.
> in thread.h: #define NICE_MIN , #define NICE_MAX ----> to make sure that the nice value is valid

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0	0   0   0   63  61  59     A
 4	4   0   0   62  61  59     A
 8	8   0   0   61  61  59     B
12	8   4   0   61  60  59	    A
16	12  4   0   60  60  59     B
20	12  8   0   60  59  59     C
24	12  8   4   60  59  58     A
28      16  8   4   59  59  58     B
32      16  12  4   59  58  58     A
36      20  12  4   58  58  58     B

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?
Answer:
> The ambiguity was choosing which thread of the same priority to run first.
> The rule we used is: the thread yields the CPU if it has less than or equal priority of
      the next maximum-priority thread


>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?
Answer:
> almost all computations of mlfqs mode done outside the interrupt context.
  the interrupt context only checks for threads to unblock.


---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?
Answer:
> We didn't use 64 queues ,queue for each priority, instead, we used only the ready queue.
  Insert the threads in the queue ordered acccording to their effective priority in the default mode,
  and according to their computed priority in advanced schedule mode.
  The priority updated every 4 ticks and the list reordered.
  Every TIME_FREQ the recent_cpu for all threads and load_avg are recalculated.
> If we have more time, we would implement the schedule using 64 queues, to avoid sorting every 4 ticks (taking more time).


>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?
Answer:
> The implementation is in a separate header file fixed-point.h
  New data type (fp) is defined to use with real values (recent_cpu & load_avg).
  Fixed-point math is done using a set of simple functions declared in the 
  	header file to be used in the scheduling computations.
> We did so, as it is a simple way to do the math, new data type is used for more readability.


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?
Answer:
> too hard, too long time, too much effort

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
